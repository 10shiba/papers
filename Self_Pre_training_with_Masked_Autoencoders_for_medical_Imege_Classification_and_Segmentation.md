# Self Pre-training with Masked Autoencoders for Medical Image Classification and Segmentation


### 題名等

**SELF PRE-TRAINING WITH MASKED AUTOENCODERS FOR MEDICAL IMAGE
CLASSIFICATION AND SEGMENTATION**

arXiv

stony Book Univ. USA and Amazon

Lei Zhou, H_uidong Liu et al.

### 概要

この論文では、Masked Autoencoder (MAE)が自然画像解析のためのVision Transformers (ViT)の事前学習に有効であることを議論しています。MAEは部分的にマスクされた入力から完全な画像を再構築することで、ViTエンコーダがマスクされた画像領域を推論するための文脈情報を集約します。著者らは、この文脈を集約する能力が医用画像領域において特に重要であると考えています。この領域では、各解剖学的構造が他の構造や領域と機能的、機械的に接続されています。事前学習のためのImageNet規模の医用画像データセットが存在しないため、著者らは医用画像解析タスクのためのMAEを用いた自己事前学習パラダイムを探求しています。この方法は、ViTを目的のデータのトレーニングセットで事前学習するため、事前学習データを取得するのが難しいシナリオにも有益です。実験結果は、MAE自己事前学習が、胸部X線疾患分類、腹部CT多臓器セグメンテーション、MRI脳腫瘍セグメンテーションなどのさまざまな医用画像タスクを大幅に向上させることを示しています。

### 背景

### 提案モデル

![スクリーンショット 2023-11-01 15.42.10.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/dbf7fbfa-2f2a-4585-96df-586936a0bf13/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.42.10.png)

- MAEによる自己事前学習
    - EncorderとDecorderを用いて行う．ViT方式が採用されていて，損失関数は平均事情誤差で示されている
- 下流タスクのための構造
    - 分類においては線形分類器を持ちいて行われる
    - 3Dセグメンテーションでは，U-Net[12]から着想を得たUNETR[9]を元に行う
    UNETRをそのまま使用している可能性が高い
    !!!!!! UNETRの調査 !!!!!!

### データ

1. **Lung Disease Classification on ChestX-ray14**:
    - ChestX-ray14は、32,717人の患者からの112,120の正面視X線画像からなる大規模なCXRデータベースです。
    - 公式の分割に基づいて分類タスクを実施し、多クラスAUCを性能指標として採用しています。
2. **Abdomen Multi-organ Segmentation on BTCV**:
    - BTCVは、放射線技師によって13の臓器が注釈された腹部CTスキャンを持つ30人の被験者からなるデータセットです。
    - 各CTボリュームは、512 x 512ピクセルの85〜198のスライスを持ち、ボクセルの空間分解能は(0.54 x 0.98 x [2.5〜5.0] mm^3)です。
    - 8つの腹部臓器に対して平均Dice類似係数(DSC)と95% Hausdorff距離(HD)を報告しています。
3. **Brain Tumor Segmentation on MSD**:
    - MSDは、Medical Segmentation Decathlon (MSD) Challengeの10のタスクの1つです。
    - セット全体には、484の多モーダル(MRI)脳スキャンが含まれています。
    - パフォーマンスは、腫瘍の核、全腫瘍、および増強腫瘍という3つの再結合領域に基づいて測定されます。

### 学習方法

1. **Data Preprocessing and Augmentation**:
    - ChestX-ray14のすべてのX線画像にヒストグラム均等化を実施。
    - BTCVでは、生の値を-175と250の間にクリップし、範囲を[0,1]内に再スケーリング。
    - BraTSでは、チャネルごとに非ゼロ領域上でインスタンスごとの正規化を実施。
2. **MAE Self Pre-training**:
    - 初期学習率(lr)はすべてのタスクで1.5e-4、重み減衰は0.05。
    - lrは、ウォームアップを伴うコサインスケジュールに従ってゼロに減少。
3. **Task Fine-tuning**:
    - ViTトレーニングを安定させるために、層ごとの学習率減衰を採用し、10%の確率でランダムなDropPathを使用。

### 評価方法

### 結果

1. MAEによる再構築
    
    ![スクリーンショット 2023-11-01 15.42.16.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/65653b8d-87f3-46b5-a46a-1b0bac723429/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.42.16.png)
    
    - 上がoriginal画像で真ん中がマスク後の画像．一番したが再現した画像である．ヒラぢから順にChestXray. BTCV, BraTSである．
    - これらの結果から高性能な再構築の可能性を示していることがわかる．
    - 最終的な目的は高品質の再構築の生成ではなく，下流のタスクの性能を向上させることである．
2. 肺の病気の分類
    
    ![スクリーンショット 2023-11-01 15.43.10.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/43046e66-6942-4342-8035-21ec6915e98c/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.43.10.png)
    
    - MAEを用いた場合ImageNet-1Kに比べて0.8%上回る
    - 何も事前学習がない時と比較すると性能が向上している
    - ViTでない場合と比較しても良い結果が得られていることがわかる．
3. 腹部多臓器セグメンテーション
    
    ![スクリーンショット 2023-11-01 15.43.05.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/8250b081-515e-44c2-bd15-29b3f2a2e077/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.43.05.png)
    
    - ImageNetで事前学習をするよりも優れている．
    - 今回はN-30の小規模なデータセットであるのにも関わらず性能が出ていることが特徴点である．
    - 一方，バックボーンの性能が先進的なDSTUNetやnnFormerやnnUnNetよりかは性能が劣っている．
4. 脳腫瘍セグメンテーション
    
    ![スクリーンショット 2023-11-01 15.47.46.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/ab24b46b-9076-4935-a977-14e9f940e3ca/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.47.46.png)
    
    - MAEが高い性能を示している
5. その他
    
    
    ![スクリーンショット 2023-11-01 15.47.51.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/1800634f-d227-4bce-b735-6ee000b4993d/37e15392-49dd-4c29-9797-be8f8dd6441d/%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%BC%E3%83%B3%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88_2023-11-01_15.47.51.png)
    

## 結論

私たちは、MAE事前学習が、さまざまな医用画像解析タスクにおけるSOTAの分類およびセグメンテーションの性能を向上させることを示しました。医用画像タスクにとって重要なことに、MAE自己事前学習は、ImageNet転送学習を含む小さなデータセットでの既存の方法を上回ります。さらに、CTとMRIの両方を含む3D医用画像でのMAEの有効性を示しています。今後の研究では、MAE事前学習の予後および結果予測タスク[28]における有効性をテストします。

## 疑問

- この場合のImageNetによる事前学習に使われた手法はなんだ？
- 自分で実際に実装することはできるのか？
- Table2にあるコードたちはすぐに実装することが可能なのか？
